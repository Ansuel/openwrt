From 3d3f94caf25cbdf18104f9ff8fb9aaebc4664a74 Mon Sep 17 00:00:00 2001
Message-ID: <3d3f94caf25cbdf18104f9ff8fb9aaebc4664a74.1738924778.git.lorenzo@kernel.org>
In-Reply-To: <74e0d25837a2960a7966616153d729e3c6d55474.1738924778.git.lorenzo@kernel.org>
References: <74e0d25837a2960a7966616153d729e3c6d55474.1738924778.git.lorenzo@kernel.org>
From: Lorenzo Bianconi <lorenzo@kernel.org>
Date: Thu, 6 Feb 2025 11:22:12 +0100
Subject: [PATCH net-next 6/6] net: airoha: Enable Rx Scatter-Gather

EN7581 SoC can receive 9k frames. Enable the reception of Scatter-Gather
(SG) frames.

Signed-off-by: Lorenzo Bianconi <lorenzo@kernel.org>
---
 drivers/net/ethernet/airoha/airoha_eth.c  | 77 ++++++++++++++---------
 drivers/net/ethernet/airoha/airoha_eth.h  |  3 +-
 drivers/net/ethernet/airoha/airoha_ppe.c  |  5 ++
 drivers/net/ethernet/airoha/airoha_regs.h | 11 ++++
 4 files changed, 66 insertions(+), 30 deletions(-)

--- a/drivers/net/ethernet/airoha/airoha_eth.c
+++ b/drivers/net/ethernet/airoha/airoha_eth.c
@@ -141,7 +141,7 @@ static void airoha_fe_maccr_init(struct
 		airoha_fe_rmw(eth, REG_GDM_LEN_CFG(p),
 			      GDM_SHORT_LEN_MASK | GDM_LONG_LEN_MASK,
 			      FIELD_PREP(GDM_SHORT_LEN_MASK, 60) |
-			      FIELD_PREP(GDM_LONG_LEN_MASK, 4004));
+			      FIELD_PREP(GDM_LONG_LEN_MASK, AIROHA_MAX_MTU));
 	}
 
 	airoha_fe_rmw(eth, REG_CDM1_VLAN_CTRL, CDM1_VLAN_MASK,
@@ -616,10 +616,10 @@ static int airoha_qdma_rx_process(struct
 		struct airoha_qdma_desc *desc = &q->desc[q->tail];
 		u32 hash, reason, msg1 = le32_to_cpu(desc->msg1);
 		dma_addr_t dma_addr = le32_to_cpu(desc->addr);
+		struct page *page = virt_to_head_page(e->buf);
 		u32 desc_ctrl = le32_to_cpu(desc->ctrl);
 		struct airoha_gdm_port *port;
-		struct sk_buff *skb;
-		int len, p;
+		int data_len, len, p;
 
 		if (!(desc_ctrl & QDMA_DESC_DONE_MASK))
 			break;
@@ -637,30 +637,42 @@ static int airoha_qdma_rx_process(struct
 		dma_sync_single_for_cpu(eth->dev, dma_addr,
 					SKB_WITH_OVERHEAD(q->buf_size), dir);
 
-		p = airoha_qdma_get_gdm_port(eth, desc);
-		if (p < 0 || !eth->ports[p]) {
-			page_pool_put_full_page(q->page_pool,
-						virt_to_head_page(e->buf),
-						true);
-			continue;
+		data_len = q->skb ? q->buf_size
+				  : SKB_WITH_OVERHEAD(q->buf_size);
+		if (data_len < len)
+			goto free_frag;
+
+		if (!q->skb) { /* first buffer */
+			q->skb = napi_build_skb(e->buf, q->buf_size);
+			if (!q->skb)
+				goto free_frag;
+
+			__skb_put(q->skb, len);
+		} else { /* scattered frame */
+			struct skb_shared_info *shinfo = skb_shinfo(q->skb);
+			int nr_frags = shinfo->nr_frags;
+
+			if (nr_frags >= ARRAY_SIZE(shinfo->frags))
+				goto free_frag;
+
+			skb_add_rx_frag(q->skb, nr_frags, page,
+					e->buf - page_address(page), len,
+					q->buf_size);
 		}
 
-		port = eth->ports[p];
-		skb = napi_build_skb(e->buf, q->buf_size);
-		if (!skb) {
-			page_pool_put_full_page(q->page_pool,
-						virt_to_head_page(e->buf),
-						true);
-			break;
-		}
+		if (FIELD_GET(QDMA_DESC_MORE_MASK, desc_ctrl))
+			continue;
+
+		p = airoha_qdma_get_gdm_port(eth, desc);
+		if (p < 0 || !eth->ports[p])
+			goto free_frag;
 
-		skb_reserve(skb, 2);
-		__skb_put(skb, len);
-		skb_mark_for_recycle(skb);
-		skb->dev = port->dev;
-		skb->protocol = eth_type_trans(skb, skb->dev);
-		skb->ip_summed = CHECKSUM_UNNECESSARY;
-		skb_record_rx_queue(skb, qid);
+		port = eth->ports[p];
+		skb_mark_for_recycle(q->skb);
+		q->skb->dev = port->dev;
+		q->skb->protocol = eth_type_trans(q->skb, port->dev);
+		q->skb->ip_summed = CHECKSUM_UNNECESSARY;
+		skb_record_rx_queue(q->skb, qid);
 
 		if (netdev_uses_dsa(port->dev)) {
 			/* PPE module requires untagged packets to work
@@ -673,22 +685,29 @@ static int airoha_qdma_rx_process(struct
 
 			if (sptag < ARRAY_SIZE(port->dsa_meta) &&
 			    port->dsa_meta[sptag])
-				skb_dst_set_noref(skb,
+				skb_dst_set_noref(q->skb,
 						  &port->dsa_meta[sptag]->dst);
 		}
 
 		hash = FIELD_GET(AIROHA_RXD4_FOE_ENTRY, msg1);
 		if (hash != AIROHA_RXD4_FOE_ENTRY)
-			skb_set_hash(skb, jhash_1word(hash, 0),
+			skb_set_hash(q->skb, jhash_1word(hash, 0),
 				     PKT_HASH_TYPE_L4);
 
 		reason = FIELD_GET(AIROHA_RXD4_PPE_CPU_REASON, msg1);
 		if (reason == PPE_CPU_REASON_HIT_UNBIND_RATE_REACHED)
 			airoha_ppe_check_skb(eth->ppe, hash);
 
-		napi_gro_receive(&q->napi, skb);
-
 		done++;
+		napi_gro_receive(&q->napi, q->skb);
+		q->skb = NULL;
+		continue;
+free_frag:
+		page_pool_put_full_page(q->page_pool, page, true);
+		if (q->skb) {
+			dev_kfree_skb(q->skb);
+			q->skb = NULL;
+		}
 	}
 	airoha_qdma_fill_rx_queue(q);
 
@@ -764,6 +783,7 @@ static int airoha_qdma_init_rx_queue(str
 			FIELD_PREP(RX_RING_THR_MASK, thr));
 	airoha_qdma_rmw(qdma, REG_RX_DMA_IDX(qid), RX_RING_DMA_IDX_MASK,
 			FIELD_PREP(RX_RING_DMA_IDX_MASK, q->head));
+	airoha_qdma_set(qdma, REG_RX_SCATTER_CFG(qid), RX_RING_SG_EN_MASK);
 
 	airoha_qdma_fill_rx_queue(q);
 
@@ -1163,7 +1183,6 @@ static int airoha_qdma_hw_init(struct ai
 	}
 
 	airoha_qdma_wr(qdma, REG_QDMA_GLOBAL_CFG,
-		       GLOBAL_CFG_RX_2B_OFFSET_MASK |
 		       FIELD_PREP(GLOBAL_CFG_DMA_PREFERENCE_MASK, 3) |
 		       GLOBAL_CFG_CPU_TXR_RR_MASK |
 		       GLOBAL_CFG_PAYLOAD_BYTE_SWAP_MASK |
--- a/drivers/net/ethernet/airoha/airoha_eth.h
+++ b/drivers/net/ethernet/airoha/airoha_eth.h
@@ -26,7 +26,7 @@
 #define AIROHA_MAX_DSA_PORTS		7
 #define AIROHA_MAX_NUM_RSTS		3
 #define AIROHA_MAX_NUM_XSI_RSTS		5
-#define AIROHA_MAX_MTU			2000
+#define AIROHA_MAX_MTU			9216
 #define AIROHA_MAX_PACKET_SIZE		2048
 #define AIROHA_NUM_QOS_CHANNELS		4
 #define AIROHA_NUM_QOS_QUEUES		8
@@ -183,6 +183,7 @@ struct airoha_queue {
 
 	struct napi_struct napi;
 	struct page_pool *page_pool;
+	struct sk_buff *skb;
 };
 
 struct airoha_tx_irq_queue {
--- a/drivers/net/ethernet/airoha/airoha_ppe.c
+++ b/drivers/net/ethernet/airoha/airoha_ppe.c
@@ -729,6 +729,11 @@ static void airoha_ppe_hw_init(struct ai
 			      FIELD_PREP(PPE_TB_ENTRY_SIZE_MASK, 0));
 
 		airoha_fe_wr(eth, REG_PPE_HASH_SEED(i), PPE_HASH_SEED);
+
+		airoha_fe_rmw(eth, REG_PPE_MTU0(i), FP0_EGRESS_MTU_MASK,
+			      FIELD_PREP(FP0_EGRESS_MTU_MASK, AIROHA_MAX_MTU));
+		airoha_fe_rmw(eth, REG_PPE_MTU2(i), FP5_EGRESS_MTU_MASK,
+			      FIELD_PREP(FP5_EGRESS_MTU_MASK, AIROHA_MAX_MTU));
 	}
 
 	if (airoha_ppe2_is_enabled(eth)) {
--- a/drivers/net/ethernet/airoha/airoha_regs.h
+++ b/drivers/net/ethernet/airoha/airoha_regs.h
@@ -296,6 +296,12 @@
 #define PPE_SRAM_HASH0_MODE_MASK		GENMASK(7, 4)
 #define PPE_SRAM_TABLE_EN_MASK			BIT(0)
 
+#define REG_PPE_MTU0(_n)			(((_n) ? PPE2_BASE : PPE1_BASE) + 0x304)
+#define FP0_EGRESS_MTU_MASK			GENMASK(13, 0)
+
+#define REG_PPE_MTU2(_n)			(((_n) ? PPE2_BASE : PPE1_BASE) + 0x30c)
+#define FP5_EGRESS_MTU_MASK			GENMASK(13, 0)
+
 #define REG_PPE_RAM_CTRL(_n)			(((_n) ? PPE2_BASE : PPE1_BASE) + 0x31c)
 #define PPE_SRAM_CTRL_ACK_MASK			BIT(31)
 #define PPE_SRAM_CTRL_DUAL_SUCESS_MASK		BIT(30)
@@ -621,10 +627,15 @@
 #define REG_RX_DELAY_INT_IDX(_n)	\
 	(((_n) < 16) ? 0x0210 + ((_n) << 5) : 0x0e10 + (((_n) - 16) << 5))
 
+#define REG_RX_SCATTER_CFG(_n)	\
+	(((_n) < 16) ? 0x0214 + ((_n) << 5) : 0x0e14 + (((_n) - 16) << 5))
+
 #define RX_DELAY_INT_MASK		GENMASK(15, 0)
 
 #define RX_RING_DMA_IDX_MASK		GENMASK(15, 0)
 
+#define RX_RING_SG_EN_MASK		BIT(0)
+
 #define REG_INGRESS_TRTCM_CFG		0x0070
 #define INGRESS_TRTCM_EN_MASK		BIT(31)
 #define INGRESS_TRTCM_MODE_MASK		BIT(30)
